# Результаты моей домашней работы по предсказанию цен автомобилей

## Файлы
1. `Lyalin_AI_HW1_Regression_with_inference_base.ipynb` со всеми проведёнными экспериментами.
2. Сохранённые дашборды: `test_dataset_profile.html`, `train_dataset_profile.html`.
3. `fastapi_prediction.py` с реализацией сервиса.
4. `pickle`-файл с сохранёнными весами модели, коэффициентами скейлинга и прочими числовыми значениями, которые могут понадобиться для инференса.
5. `README.md` с выводами о проделанной работе.

## Выводы

### Что было сделано
1. Проведён **EDA** (исследовательский анализ данных): 
   - Данные проанализированы на наличие пропусков, дубликатов и ненужных колонок.
   - Отрисованы `pairplot`-ы и корреляционные матрицы.
   - Сделаны выводы о важности признаков.

2. Созданы автоматические отчёты с помощью библиотеки `ydata_profiling`.

3. Данные обработаны:
   - Удалены дубликаты.
   - Пропуски заполнены медианой.
   - Удалены ненужные категориальные колонки.
   - Извлечены важные числовые признаки из категориальных колонок.
   - Реализована стандартизация числовых признаков.
   - Выполнено OHE и MTE кодирование категориальных признаков.

4. Построено множество моделей линейной регрессии:
   - Линейная регрессия на числовых признаках.
   - Линейная регрессия на стандартизированных числовых признаках.
   - Lasso на числовых признаках.
   - ElasticNet регрессия.
   - Ridge регрессия на закодированных категориальных фичах.

5. Реализовано API на FastAPI для предсказания стоимости автомобилей на новых данных.

### Метрики моделей на тесте

| Модель                                      | R^2 на тесте |
|---------------------------------------------|--------------|
| Линейная регрессия на числовых признаках    | 0.594        |
| Линейная регрессия на стандартизированных числовых признаках | 0.594        |
| Lasso на числовых признаках                 | 0.594        |
| ElasticNet регрессия                        | 0.572        |
| Ridge регрессия на закодированных категориальных фичах | 0.847        |

### Что дало наибольший буст в качестве
- Наибольший буст дало обучение на стандартизированных данных с энкодингом категориальных фичей и использование Ridge линейной модели с регуляризацией.
- Лучшая модель: **Ridge регрессия**, R^2 на тесте: 0.847, MSE: 8.79 * 10^10.

### Что сделать не вышло и почему
1. Не удалось улучшить качество модели с помощью других методов регуляризации.
2. Не удалось заполнить пропуски в скрипте FastAPI из `pd.Series`. Пришлось захардкодить медианы признаков из тренировочных данных.

### Скриншоты работы сервиса fastapi:
1. Pycharm
[1](homework_ml_1/screens/1.png)
